# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: **количество созданных объектов по данным ObjectSpace, поле :TOTAL**

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за ~10 секунд на данных 50к строк исходного файла

Вот как я построил `feedback_loop`: 
- внесение изменений в код, попытаться сократить количество создаваемых объектов кодом
- запуск тестов – тесты должны быть зеленые
- формирование отчета профилировщика – анализ топа проблем
- запуск программы – изменилась ли метрика :TOTAL
- поиск точек роста
- к шагу 1

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*
гемом `memory_profiler`, ruby-prof, stackprof, valgrind


Вот какие проблемы удалось найти и решить

### Ваша находка №0
На нулевом шаге перевел программу на потоковый стиль обработки данных
Это сходу дало существенный прирост метрики
ObjectSpace.count_objects[:TOTAL] => **2_372_250 -> 2_086_508**

### Ваша находка №1
- Ruby prof, graph report указывал на метод add_stats(50% памяти от всего объема программы), а внутри него самыми затратными являлись операции Array#map(SELF=4.09%) и Date.parse(SELF=18.41%)
Я решил взять за Date.parse
- Этот метод оказался не нужен, так как данные приходят уже в нужном формате
- Метрика ObjectSpace[:TOTAL] улучшилась почти вдвое **2_047_784 -> 1_351_604**
- add_stats перестал показываться в топе отчета ruby-prof graph

### Ваша находка №2
- Отчет ruby-prof показывал в топе String.split – эта операция забирала 50% ресурсов
Также она находилась в топ-5 проблем по memory_profiler
21.69 MB  /Users/otmosina/work/learn/course/rails-optimization-task2/task-2.rb:65
Решил отпимизировать ее
- Метод вызывался лишний раз в функциях parse_session и parse_user – убрал вызовы оттуда, оставив один
- Метрика ObjectSpace[:TOTAL] улучшилась **1_351_604 -> 1_051_608**
- Отчет ruby-prof изменился – String.split ушел из топа

### Ваша находка №3
- Отчет RubyProf(MEMORY mode) показал что в топе вновь оказался метод add_stats
Построенное дерево в qcachegrind показывает, что внутри add_stats топ памяти потребляется в Array.map
Далее спускаясь по дереву видим, что внутри Array.map вызывается upcase и потребляет много памяти. Решил разобраться с upcase
- В add_stats метод upcase вызывает два раза на одних и тех же данных(каждый раз создавая новые лишние строки). Вынес вызов этого метода в одно место
- Метрика ObjectSpace[:TOTAL] улучшилась **1_051_608 -> 919_545**
- Отчет RubyProf(MEMORY mode) изменился – upcase пропал из дерева отчета

### Ваша находка №4
- Отчет RubyProf(MEMORY mode) показал, что в топе вновь оказался метод add_stats 25.26% памяти
Построенное дерево в qcachegrind показывает, что внутри add_stats топ памяти потребляется в:
 Array.map(12.45%) -> String.strip(4.72%) (при парсинге строки файла добавлялся \n в конце строки)
- Убрал String.strip из метода, а также убрать дублирующиеся вызовы map
- Убрал String::strip – Метрика ObjectSpace[:TOTAL] улучшилась **919_545 -> 913_426**
Стал создавать массивы с браузерами и временем перед формированием json, чтобы не дублировать одинаковые массивы, по которым делаются операции min||max и выбираются наборы с нужными браузерами. Метрика ObjectSpace[:TOTAL] улучшилась **913_426 -> 866_962** 


- После решенной проблемы со String::strip –  Отчет RubyProf(MEMORY mode) изменился add_stats 25.26% -> 20.54% | Array.map 12.45% -> 7.73%
После решенной проблемы с Array.map Отчет RubyProf(MEMORY mode) изменился add_stats 20.54% -> 16.22% | Array.map 7.73% -> 2.72%


### Ваша находка №5
- Отчет RubyProf(MEMORY mode) показал что в топе вновь оказался метод add_stats ~16% памяти
После предыдущей находки подсветилась проблема String::+(1.8%)
- Заменил + на << чтобы не создавать лишних String объектов
- ObjectSpace[:TOTAL] улучшилась **866_962 ->  851_883**
- Проблема String+ ушла из отчета qcachegrind, add_stats 16.22% -> 14.67%

### Ваша находка №6
- stackprof показывал в топе Object#parse_session(15%). Внутри метода указывал на строчки upcase & strip
- заменил методы на те же только с ! чтобы не создавалось дополнительных строк
- ObjectSpace[:TOTAL] улучшилась **851_883 ->  773_220**
- из отчета stackprof parse_session ушло с первого места
 Object#parse_session(15.2% -> 5.6%)

### Ваша находка №7
- Отчет RubyProf(graph mode) указывал по-прежнему на метод add_stats,
В топе внутри метода был метод sort и неподалеку reverse
- заменил методы на методы с bang!
- ObjectSpace[:TOTAL] улучшилась **773_220 -> 743_866**
- sort и reverse исчезли из топа add_stats

### Ваша находка №8
- Отчет RubyProf(graph mode) указывал по-прежнему на метод add_stats,
в топе были Array#any? и Array#all?
- попробовал заменил проверку по регулярному выражению 
{ |b| b =~ /INTERNET EXPLORER/ } на b.start_with?("INTERNET EXPLORER"). 
Оказалось, что при таком подходе не создается лишних объектов(T_MATCH)
и строк тоже новых не создается так как "INTERNET EXPLORER" – замороженная строка
- ObjectSpace[:TOTAL] улучшилась **743_866 -> 712_486**
- all? и any? ушли из топа отчета из метода add_stats

### Ваша находка №9
- Отчет RubyProf(graph mode) указывал на метод String split в топе
На каждой итерации по строкам файла этот метод создавал 4-5 дополнительных строк, а также объекты хеша в методе parse_user

- решил избавиться от создания лишних строк, убрал сплит и использовал match
– ObjectSpace[:TOTAL] улучшилась **712_486 -> 689_252**
- String split по-прежнему в топе

### Ваша находка №10
- проведем оптимизацию String::split для секций sessions. По отчету RubyProf(graph mode) этот метод по-прежнему в топе
- заменяем split на match и достаем только используемые поля
-  ObjectSpace[:TOTAL] улучшилась **689_252 -> 604_877**
- String.split ушел из топа проблем

### Ваша находка №11
- По отчету RubyProf(graph report) теперь в топе проблем Object#parse_session
- Внутри метода создается объект хеша. Мы можем обойтись и без создания лишних хешей и доставать данные из готового результата работы метода match
– ObjectSpace[:TOTAL] улучшилась **604_877 -> 562_487** за счет уменьшения :T_HASH 119390 -> 77085
- Object#parse_session ушел из топа проблем

### Ваша находка №12
- Отчет RubyProf(graph report) указывал в топе на проблему File.write
В коде запись данных в файл было представлено тремя строками
- Сделать запись файл данных один раз, заодно убрал создание лишней строки при формировании user_name перед записью(убрал создание переменной – пишу данные по имени сразу в файл)
– ObjectSpace[:TOTAL] улучшилась **562_487 -> 452_841** за счет уменьшения 
:T_FILE(23100 -> 7707) :T_HASH(77085 -> 31019) :T_STRING(328540 -> 292313)
- Метод File.write ушел из топа проблем репорта

### Ваша находка №13
После всех оптимизаций я решил наконец проверить, как ведет себя программа на больших данных.
Обнаружил, что с увеличением объема данных – программа растет по памяти, не смотря на все оптимизации.
Запустил Massif – рост потребления памяти примерно линейный, доходит до 370 mb в пике

<img width="801" alt="Pasted Graphic 21" src="https://user-images.githubusercontent.com/2257408/117532905-67160000-b01c-11eb-8e36-a25334e2afe0.png">


Получается, я где-то оставляю объекты, которые не удаляет сборщик, которые накапливаются по ходу выполнения.
Стал рефакторить код и увидел массив all_browsers, которые растет на протяжении всей работы программы.
Убрал ненужное добавление и заново запустил Massif
График стал прямым. В пике 37.2 Mb

<img width="1109" alt="Pasted Graphic" src="https://user-images.githubusercontent.com/2257408/117532941-814fde00-b01c-11eb-969e-18568e826a95.png">


Метрика ObjectSpace[:TOTAL] на исследуемых небольших данных не изменилась

### Ваша находка №14
Получив на предыдущем шаге результат, который укладывается в бюджет, я решил заоптимизировать очевидные небольшие вещи
заменить массив session для одного пользователя на счетчик сессий
прирост метрики ObjectSpace[:TOTAL] **446_728 -> 438_984**

### Ваша находка №15
Заменил структуру данных для массива всех браузеров, использовал Set
Метрика незначительно ухудшилась ObjectSpace[:TOTAL] **438_984 -> 441_025**
Решил оставить Set, так как ухудшение незначительное и никак не влияет на конечный бюджет

### Ваша находка №16
На каждой итерации, если попадался пользователь я создавал новый объект файла, чтобы записать в результирующий файл данные пользователя
```
File.write('result.json', "\"#{user[3]} #{user[4]}\":#{add_stats.to_json},", mode: 'a')
```
Убрал это, открыв файл на запись в начале программы и закрыв в конце
прирост метрики ObjectSpace[:TOTAL] **441_025 -> 402300** за счет T_FILE 7712 -> 12 и T_HASH 30914 -> 7814



## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы(ObjectSpace[:TOTAL] кол-во создаваемых объектов за время работы программы на файле 50к строк) с 2_372_250 до 402_300 и уложиться в заданный бюджет – на полном объеме данных по графику Maffif программа потребляет в пике 37.2 Mb

*Какими ещё результами можете поделиться*
- File.write('result.json', '1', mode: 'a') Создает 3 объекта T_FILE и около 9 объектов T_HASH
- Программа не течет по памяти, значит возможно обработать и файлы большего объема
- время обработки данных ~10 секунд, что в 3 раза меньше времени полученном во время первого задания по оптимизации cpu

Тесты проводились на Apple M1, 8Gb MEMORY
## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написал тесты.
В первом проверяю метрику, по которой строил исследование – количество созданных объектов при выключенном GC, не должно быть больше 500_000
```
    it 'create not more than 500_000 object with disable GC' do
        work("data/data#{DATA_SIZE}.txt", true)
        expect(ObjectSpace.count_objects[:TOTAL]).to be < MAX_TOTAL_OBJECTS
    end
```
Во втором проверяю, что программа укладывается в заданный бюджет по памяти – меньше 70 mb
```
    it 'consumes not more than memory budget(70 mb)' do 
        pid = Process.fork do
            work("data/data#{DATA_SIZE}.txt", false)
        end
        expect(process_mem_mb(pid)).to be < MAX_MEMORY_MB 
        Process.waitall
    end
    
```
